{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "###################       get_p_value      ######################\n",
    "#################################################################\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import poisson, norm, kstest\n",
    "import numdifftools\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "def get_p_value(ydata, binvals, npar, make_plot, mask=[], verbose=1, yerr=None, return_teststat = False):\n",
    "    \n",
    "    ydata = np.array(ydata)\n",
    "    #Assume poisson is gaussian with N+1 variance\n",
    "    if not yerr:\n",
    "        yerr = np.sqrt(ydata+1)\n",
    "    else:\n",
    "        yerr = np.array(yerr)\n",
    "\n",
    "    if (npar == 3):\n",
    "        def fit_func(x,p1,p2,p3):\n",
    "            #see the ATLAS diboson resonance search: https://arxiv.org/pdf/1708.04445.pdf.\n",
    "            xi = 0.\n",
    "            y = x/13000.\n",
    "            return p1*(1.-y)**(p2-xi*p3)*y**-p3\n",
    "    \n",
    "    elif (npar == 4):\n",
    "        def fit_func(x,p1,p2,p3,p4):\n",
    "            # see https://cds.cern.ch/record/2256663/files/B2G-17-001-pas.pdf\n",
    "            # see the ATLAS dijet resonance search: https://arxiv.org/pdf/1806.00843.pdf.\n",
    "            y = x/13000.\n",
    "       \n",
    "            return (p1*(1.-y)**p2) / (y**(p3 + p4*np.log(y)))\n",
    "    \n",
    "    elif (npar == 5):\n",
    "        def fit_func(x,p1,p2,p3,p4,p5):\n",
    "            # see https://cds.cern.ch/record/2256663/files/B2G-17-001-pas.pdf\n",
    "            # see the ATLAS dijet resonance search: https://arxiv.org/pdf/1806.00843.pdf.\n",
    "            y = x/13000.\n",
    "        \n",
    "            return (p1*(1.-y)**p2) / (y**(p3 + p4*np.log(y) + p5*(np.log(y))**2))\n",
    "\n",
    "    else:\n",
    "        print('Wrong number of parameters for the fit function')\n",
    "    \n",
    "    \n",
    "    xdata = np.array([0.5*(binvals[i]+binvals[i+1]) for i in range(0,len(binvals)-1)])\n",
    "    xwidths = np.array([-binvals[i]+binvals[i+1] for i in range(0,len(binvals)-1)])\n",
    "\n",
    "    \n",
    "    #Assuming inputs are bin counts, this is needed to get densities. Important for variable-width bins\n",
    "    ydata = np.array(ydata) * 100 / xwidths\n",
    "    yerr = np.array(yerr)*100/ np.array(xwidths)\n",
    "\n",
    "    #Least square fit, masking out the signal region\n",
    "    if len(mask) > 0:\n",
    "        try:\n",
    "            limits = (10**-50, np.inf)\n",
    "            popt, pcov = curve_fit(fit_func, np.delete(xdata,mask), np.delete(ydata,mask), bounds=limits,\n",
    "                                   sigma=np.delete(yerr,mask),max_nfev=1000000,absolute_sigma=True)\n",
    "        except RuntimeError:\n",
    "            print(\"Error - curve_fit failed\")\n",
    "            return 1\n",
    "    else:\n",
    "        try:\n",
    "            popt, pcov = curve_fit(fit_func, xdata, ydata, sigma=yerr,maxfev=1000000)\n",
    "        except RuntimeError:\n",
    "            print(\"Error - curve_fit failed\")\n",
    "            return 1\n",
    "    if verbose:\n",
    "        print('fit params: ', popt)\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "    if (npar == 3):\n",
    "        ydata_fit = np.array([fit_func(x,popt[0],popt[1],popt[2]) for x in xdata])\n",
    "    elif (npar == 4):\n",
    "        ydata_fit = np.array([fit_func(x,popt[0],popt[1],popt[2],popt[3]) for x in xdata])\n",
    "    elif (npar == 5):\n",
    "        ydata_fit = np.array([fit_func(x,popt[0],popt[1],popt[2],popt[3],popt[4]) for x in xdata])\n",
    "    else:\n",
    "        print('Wrong number of parameters for the fit function')\n",
    "    \n",
    "    # Sanity check\n",
    "    if len(mask) > 0:\n",
    "        residuals = np.delete((ydata - ydata_fit)/yerr,mask)\n",
    "    else:\n",
    "        residuals = np.delete((ydata - ydata_fit)/yerr,mask)\n",
    "    distance, p_val = kstest(residuals, norm(loc=0,scale=1).cdf)\n",
    "    \n",
    "    if (p_val < 0.1):\n",
    "        print('Warning: p-value for bg only fit is p0 = %.3f' % p_val)                 \n",
    "                             \n",
    "    \n",
    "    #Check that the function is a good fit to the sideband\n",
    "    \n",
    "    if verbose > 0:\n",
    "        if len(mask) > 0:\n",
    "            residuals = np.delete((ydata - ydata_fit)/yerr,mask)\n",
    "        else:\n",
    "            residuals = np.delete((ydata - ydata_fit)/yerr,mask)\n",
    "        print(\"Goodness: \", kstest(residuals, norm(loc=0,scale=1).cdf))\n",
    "        print('\\n')\n",
    "    \n",
    "    if len(mask) == 0:\n",
    "        pass\n",
    "    \n",
    "    # The following code is used to get the bin errors by propagating the errors on the fit params\n",
    "\n",
    "    if (npar == 3):\n",
    "        def fit_func_array(parr):\n",
    "            #see the ATLAS diboson resonance search: https://arxiv.org/pdf/1708.04445.pdf.\n",
    "            p1, p2, p3 = parr\n",
    "            xi = 0.\n",
    "            return np.array([p1*(1.-(x/13000.))**(p2-xi*p3)*(x/13000.)**-p3 for x in xdata])\n",
    "    \n",
    "    elif (npar == 4):\n",
    "        def fit_func_array(parr):\n",
    "            # see https://cds.cern.ch/record/2256663/files/B2G-17-001-pas.pdf\n",
    "            # see the CMS dijet resonance search: https://arxiv.org/pdf/1806.00843.pdf.\n",
    "            p1, p2, p3, p4 = parr\n",
    "        \n",
    "            return np.array([(p1*(1.-(x/13000.))**p2) / ((x/13000.)**(p3 + p4*np.log(x/13000.))) for x in xdata])  \n",
    "    \n",
    "    elif (npar == 5):\n",
    "        def fit_func_array(parr):\n",
    "            # see https://cds.cern.ch/record/2256663/files/B2G-17-001-pas.pdf\n",
    "            # see the ATLAS dijet resonance search: https://arxiv.org/pdf/1806.00843.pdf.\n",
    "            p1, p2, p3, p4, p5 = parr\n",
    "        \n",
    "            return np.array([(p1*(1.-(x/13000.))**p2) / ((x/13000.)**(p3 + p4*np.log(x/13000.) + p5*(np.log(x/13000.))**2)) for x in xdata])  \n",
    "    \n",
    "    else:\n",
    "        print('Wrong number of parameters for the fit function')\n",
    "    \n",
    "    \n",
    "    jac=numdifftools.core.Jacobian(fit_func_array)\n",
    "    x_cov=np.dot(np.dot(jac(popt),pcov),jac(popt).T)\n",
    "    #For plot, take systematic error band as the diagonal of the covariance matrix\n",
    "    y_unc=np.sqrt([row[i] for i, row in enumerate(x_cov)])\n",
    "    #print(y_unc)\n",
    "    \n",
    "    if (make_plot == True):\n",
    "        plt.fill_between(xdata,ydata_fit+y_unc,ydata_fit-y_unc,color='gray',alpha=0.4)\n",
    "        plt.hist(signal_test[:,15], bins=bins, facecolor='y', alpha=0.2, label='signal')\n",
    "        #plt.errorbar(xdata, ydata,yerr,None, 'bo', label='data',markersize=3)\n",
    "#        plt.errorbar(np.delete(xdata, [mpeak_ind-5-start, mpeak_ind-4-start, mpeak_ind-3-start, mpeak_ind-2-start, mpeak_ind-1-start, mpeak_ind-start, mpeak_ind+1-start, mpeak_ind+2-start, mpeak_ind+3-start, mpeak_ind+4-start, mpeak_ind+5-start, mpeak_ind+6-start]), \n",
    "#                     np.delete(ydata, [mpeak_ind-5-start, mpeak_ind-4-start, mpeak_ind-3-start, mpeak_ind-2-start, mpeak_ind-1-start, mpeak_ind-start, mpeak_ind+1-start, mpeak_ind+2-start, mpeak_ind+3-start, mpeak_ind+4-start, mpeak_ind+5-start, mpeak_ind+6-start]),\n",
    "#                     np.delete(yerr, [mpeak_ind-5-start, mpeak_ind-4-start, mpeak_ind-3-start, mpeak_ind-2-start, mpeak_ind-1-start, mpeak_ind-start, mpeak_ind+1-start, mpeak_ind+2-start, mpeak_ind+3-start, mpeak_ind+4-start, mpeak_ind+5-start, mpeak_ind+6-start]),\n",
    "#                     None, 'bo', label='data', markersize=4, marker='o')\n",
    "        plt.errorbar(np.delete(xdata, [mpeak_ind-1-start, mpeak_ind-start, mpeak_ind+1-start]), \n",
    "                     np.delete(ydata, [mpeak_ind-1-start, mpeak_ind-start, mpeak_ind+1-start]),\n",
    "                     np.delete(yerr, [mpeak_ind-1-start, mpeak_ind-start, mpeak_ind+1-start]),\n",
    "                     None, 'bo', label='data', markersize=4, marker='o')\n",
    "        plt.errorbar(xdata[mpeak_ind-1-start:mpeak_ind+2-start], \n",
    "                     ydata[mpeak_ind-1-start:mpeak_ind+2-start],\n",
    "                     yerr[mpeak_ind-1-start:mpeak_ind+2-start], \n",
    "                     None, 'bo', label='data', markersize=4, marker='x')\n",
    "        \n",
    "        plt.plot(xdata, ydata_fit, 'r--', label='data')\n",
    "        plt.semilogy()\n",
    "        plt.ylabel(r'Num events / $160 \\; \\mathrm{GeV}$')\n",
    "        plt.xlabel(r'$m_{JJ} \\; \\mathrm{GeV}$')\n",
    "        plt.tick_params(which='both', direction='out', bottom=True, left=True, right=True)\n",
    "        plt.minorticks_on()\n",
    "        plt.ylim(ymin=0.8)\n",
    "\n",
    "        \n",
    "    if (npar == 3):\n",
    "        def signal_fit_func_array(parr):\n",
    "            #see the ATLAS diboson resonance search: https://arxiv.org/pdf/1708.04445.pdf.\n",
    "            p1, p2, p3 = parr\n",
    "            xi = 0.\n",
    "            return np.array([np.sum([p1*(1.-(x/13000.))**(p2-xi*p3)*(x/13000.)**-p3*xwidths[mask[i]]/100 for i, x in enumerate(xdata[mask])])]) \n",
    "        \n",
    "    elif (npar == 4):\n",
    "        def signal_fit_func_array(parr):\n",
    "            # see https://cds.cern.ch/record/2256663/files/B2G-17-001-pas.pdf\n",
    "            # see the ATLAS dijet resonance search: https://arxiv.org/pdf/1806.00843.pdf.\n",
    "            p1, p2, p3, p4 = parr\n",
    "            return np.array([np.sum([(p1*(1.-(x/13000.))**p2) / ((x/13000.)**(p3 + p4*np.log(x/13000.)))*xwidths[mask[i]]/100 for i, x in enumerate(xdata[mask])])]) \n",
    "    \n",
    "    elif (npar == 5):\n",
    "        def signal_fit_func_array(parr):\n",
    "            # see https://cds.cern.ch/record/2256663/files/B2G-17-001-pas.pdf\n",
    "            # see the ATLAS dijet resonance search: https://arxiv.org/pdf/1806.00843.pdf.\n",
    "            p1, p2, p3, p4, p5 = parr\n",
    "            return np.array([np.sum([(p1*(1.-(x/13000.))**p2) / ((x/13000.)**(p3 + p4*np.log(x/13000.) + p5*(np.log(x/13000.))**2))*xwidths[mask[i]]/100 for i, x in enumerate(xdata[mask])])])\n",
    "    \n",
    "    else:\n",
    "        print('Wrong number of parameters for the fit function')\n",
    "    \n",
    "    \n",
    "    #Get covariance matrix of prediction uncertainties in the signal region\n",
    "    jac=numdifftools.core.Jacobian(signal_fit_func_array)\n",
    "    x_signal_cov=np.dot(np.dot(jac(popt),pcov),jac(popt).T)\n",
    "    #Inverse signal region covariance matrix:\n",
    "    inv_x_signal_cov = inv(x_signal_cov)\n",
    "    \n",
    "    #Get observed and predicted event counts in the signal region\n",
    "    obs = np.array([np.sum(np.array(ydata)[mask]*np.array(xwidths)[mask]/100)])\n",
    "    \n",
    "    if (npar == 3):\n",
    "        expected = np.array([np.sum([fit_func(xdata[targetbin],popt[0],popt[1],popt[2])*xwidths[targetbin]/100 for targetbin in mask])])\n",
    "    elif (npar == 4):\n",
    "        expected = np.array([np.sum([fit_func(xdata[targetbin],popt[0],popt[1],popt[2],popt[3])*xwidths[targetbin]/100 for targetbin in mask])])\n",
    "    elif (npar == 5):\n",
    "        expected = np.array([np.sum([fit_func(xdata[targetbin],popt[0],popt[1],popt[2],popt[3],popt[4])*xwidths[targetbin]/100 for targetbin in mask])])    \n",
    "    else:\n",
    "        print('Wrong number of parameters for the fit function')\n",
    "        \n",
    "    #Negative numerator of log likelihood ratio, for signal rate mu = 0\n",
    "    def min_log_numerator(expected_nuis_arr):\n",
    "        #expected_nuis_arr is the array of systematic background uncertainty nuisance parameters\n",
    "        #These are event rate densities\n",
    "        expected_nuis_arr = np.array(expected_nuis_arr)\n",
    "        to_return = 0\n",
    "        #Poisson terms\n",
    "        for i, expected_nuis in enumerate(expected_nuis_arr):\n",
    "            #Poisson lambda. Have to rescale nuisance constribution by bin width\n",
    "            my_lambda = expected[i]+expected_nuis_arr[i]\n",
    "            #Prevent negative predicted rates\n",
    "            if my_lambda < 10**-10:\n",
    "                my_lambda = 10**-10\n",
    "            #Poisson term. Ignore the factorial piece which will cancel in likelihood ratio\n",
    "            to_return = to_return + (obs[i]*np.log(my_lambda) - my_lambda)\n",
    "            \n",
    "        #Gaussian nuisance term\n",
    "        nuisance_term = -0.5*np.dot(np.dot(expected_nuis_arr,inv_x_signal_cov),expected_nuis_arr)\n",
    "        to_return = to_return + nuisance_term\n",
    "        return -to_return\n",
    "\n",
    "    def jac_min_log_numerator(expected_nuis_arr):\n",
    "        #expected_nuis_arr is the array of systematic background uncertainty nuisance parameters\n",
    "        #These are event rate densities\n",
    "        expected_nuis_arr = np.array(expected_nuis_arr)\n",
    "        to_return = np.array([0.])\n",
    "        #Poisson terms\n",
    "        #Poisson lambda. Have to rescale nuisance constribution by bin width\n",
    "        my_lambda = expected+expected_nuis_arr\n",
    "        dmy_lambda = np.array([1.])\n",
    "        #Prevent negative predicted rates\n",
    "        my_lambda[my_lambda < 10**-10] = np.ones(len(my_lambda[my_lambda < 10**-10])) * 10**-10\n",
    "        dmy_lambda[my_lambda < 10**-10] = 0\n",
    "        #Poisson term. Ignore the factorial piece which will cancel in likelihood ratio\n",
    "        to_return = to_return + (obs*dmy_lambda/my_lambda - dmy_lambda)\n",
    "        #Gaussian nuisance term\n",
    "        nuisance_term = -np.dot(inv_x_signal_cov,expected_nuis_arr)\n",
    "        to_return = to_return + nuisance_term\n",
    "        return -to_return\n",
    "    \n",
    "    #Initialization of nuisance params\n",
    "    expected_nuis_array_init = [0.02]\n",
    "    \n",
    "    #shift log likelihood to help minimization algo\n",
    "    def rescaled_min_log_numerator(expected_nuis_arr):\n",
    "        return min_log_numerator(expected_nuis_arr) - min_log_numerator(expected_nuis_array_init)\n",
    "    \n",
    "    #Perform minimization over nuisance parameters. Set bounds for bg nuisance at around 8 sigma.\n",
    "    bnds=[[-8*y_unc[mask[0]],16*y_unc[mask[0]]]]\n",
    "    minimize_log_numerator = minimize(rescaled_min_log_numerator,\n",
    "                                      expected_nuis_array_init,\n",
    "                                      jac=jac_min_log_numerator,\n",
    "                                      bounds=bnds)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"numerator: \",  minimize_log_numerator.items(),'\\n')\n",
    "        \n",
    "    #Now get likelihood ratio denominator\n",
    "    def min_log_denom(nuis_arr):\n",
    "        #nuis_arr contains the bg systematics and also the signal rate\n",
    "        expected_nuis_arr = np.array(nuis_arr)[:1]\n",
    "        #print(expected_nuis_arr)\n",
    "        mu = nuis_arr[1]\n",
    "        #Signal prediction\n",
    "        pred = [mu]\n",
    "        to_return = 0\n",
    "        #Poisson terms\n",
    "        for i, expected_nuis in enumerate(expected_nuis_arr):\n",
    "            #Poisson lambda\n",
    "            my_lambda = expected[i]+expected_nuis_arr[i] + pred[i]\n",
    "            #Prevent prediction from going negative\n",
    "            if my_lambda < 10**-10:\n",
    "                my_lambda = 10**-10\n",
    "            #Poisson term. Ignore the factorial piece which will cancel in likelihood ratio\n",
    "            to_return = to_return + (obs[i]*np.log(my_lambda) - my_lambda)\n",
    "\n",
    "        #Gaussian nuisance term\n",
    "        nuisance_term = -0.5*np.dot(np.dot(expected_nuis_arr,inv_x_signal_cov),expected_nuis_arr)\n",
    "        to_return = to_return + nuisance_term\n",
    "        return -to_return\n",
    "\n",
    "    def jac_min_log_denom(nuis_arr):\n",
    "        #expected_nuis_arr is the array of systematic background uncertainty nuisance parameters\n",
    "        #These are event rate densities\n",
    "        expected_nuis_arr = np.array(nuis_arr)[:1]\n",
    "        mu = nuis_arr[1]\n",
    "        pred = [mu]\n",
    "        to_return_first = np.array([0.])\n",
    "        #Poisson terms\n",
    "        #Poisson lambda. Have to rescale nuisance constribution by bin width\n",
    "        my_lambda = expected+expected_nuis_arr+pred\n",
    "        dmy_lambda = np.array([1.])\n",
    "        #Prevent prediction from going negative\n",
    "        my_lambda[my_lambda < 10**-10] = np.ones(len(my_lambda[my_lambda < 10**-10])) * 10**-10\n",
    "        dmy_lambda[my_lambda < 10**-10] = 0\n",
    "        #Poisson term. Ignore the factorial piece which will cancel in likelihood ratio\n",
    "        to_return_first = to_return_first + (obs*dmy_lambda/my_lambda - dmy_lambda)\n",
    "        #Gaussian nuisance term\n",
    "        nuisance_term = -np.dot(inv_x_signal_cov,expected_nuis_arr)\n",
    "        to_return_first = to_return_first + nuisance_term\n",
    "        \n",
    "        to_return_last = np.array([0.])\n",
    "        \n",
    "        dpred = np.array([[1.]])\n",
    "        \n",
    "        my_lambda = expected+expected_nuis_arr+pred\n",
    "        dmy_lambda = dpred\n",
    "        to_return_last = np.dot((obs/my_lambda),dmy_lambda.T) - np.sum(dmy_lambda,axis=1)\n",
    "        \n",
    "        return -np.append(to_return_first, to_return_last)\n",
    "    \n",
    "    #initizalization for minimization\n",
    "    nuis_array_init = [0.01,1.]\n",
    "    \n",
    "    #Shift log likelihood for helping minimization algo.\n",
    "    def rescaled_min_log_denom(nuis_arr):\n",
    "        return min_log_denom(nuis_arr) - min_log_denom(nuis_array_init)\n",
    "    \n",
    "    bnds = ((None,None),(None,None))\n",
    "    minimize_log_denominator = minimize(rescaled_min_log_denom,nuis_array_init,\n",
    "                                        jac=jac_min_log_denom,\n",
    "                                        bounds=bnds)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Denominator: \",  minimize_log_denominator.items(),'\\n')\n",
    "        \n",
    "    if minimize_log_denominator.x[-1] < 0:\n",
    "        Zval = 0\n",
    "        neglognum = 0\n",
    "        neglogden = 0\n",
    "    else:\n",
    "        neglognum = min_log_numerator(minimize_log_numerator.x)\n",
    "        neglogden = min_log_denom(minimize_log_denominator.x)\n",
    "#        Zval = np.sqrt(2*(neglognum - neglogden))\n",
    "        \n",
    "#        print(neglognum - neglogden)\n",
    "        if ((neglognum - neglogden) >= 0):\n",
    "            Zval = np.sqrt(2*(neglognum - neglogden))\n",
    "        elif ((neglognum - neglogden) > -0.25):\n",
    "            Zval = np.sqrt(2*np.abs(neglognum - neglogden))\n",
    "        else:\n",
    "            Zval = np.sqrt(2*np.abs(neglognum - neglogden))\n",
    "            print('Sqrt of potentially large negative number, fit might not be reliable')\n",
    "      \n",
    "    \n",
    "    p0 = 1-norm.cdf(Zval)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"z = \", Zval)\n",
    "        print(\"p0 = \", p0)\n",
    "\n",
    "    if (make_plot == True):\n",
    "        plt.title('SR masked out | p0 = %.1e' % p0)\n",
    "        plt.show()\n",
    "\n",
    "    if return_teststat:\n",
    "        return p0, 2*(neglognum - neglogden)\n",
    "    else:\n",
    "        return p0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
